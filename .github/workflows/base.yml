name: Test

on:
  push:
    branches:
      - master
      - gh-wf-v3-local
  pull_request:
    branches:
      - master

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]   
        python-version: ['3.10'] 
      fail-fast: false

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Set up uv
      uses: astral-sh/setup-uv@v7

    - name: Install dependencies with uv
      run: |
        uv sync
        uv pip install transformers>=4.0.0

    - name: Add nanochat to PYTHONPATH (Unix)
      if: runner.os != 'Windows'
      run: |
        echo "PYTHONPATH=$(pwd):$PYTHONPATH" >> $GITHUB_ENV

    - name: Add nanochat to PYTHONPATH (Windows)
      if: runner.os == 'Windows'
      run: |
        echo "PYTHONPATH=$PWD;$env:PYTHONPATH" >> $env:GITHUB_ENV

    - name: Run pytest
      run: |
        uv run pytest tests/ --maxfail=5 

  test-cuda:
    runs-on: ubuntu-latest
    container:
      image: pytorch/pytorch:2.1.0-cuda11.8-cudnn8-devel
    strategy:
      matrix:
        python-version: ['3.10']
      fail-fast: false

    steps:
    - name: Install system dependencies and cleanup
      run: |
        apt-get update
        apt-get install -y git curl
        # Clean up to free disk space
        apt-get clean
        rm -rf /var/lib/apt/lists/*
        df -h

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up uv
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    - name: Install dependencies (excluding torch)
      run: |
        export PATH="$HOME/.local/bin:$PATH"
        # Create venv with system site packages to access container's PyTorch
        uv venv --system-site-packages
        
        # Install dependencies manually, excluding torch to avoid disk space issues
        uv pip install datasets>=4.0.0
        uv pip install fastapi>=0.117.1
        uv pip install files-to-prompt>=0.6
        uv pip install "numpy==1.26.4"
        uv pip install psutil>=7.1.0
        uv pip install regex>=2025.9.1
        uv pip install setuptools>=80.9.0
        uv pip install tiktoken>=0.11.0
        uv pip install tokenizers>=0.22.0
        # Skip torch - use container's version
        uv pip install uvicorn>=0.36.0
        uv pip install wandb>=0.21.3
        uv pip install transformers>=4.0.0
        
        # Install test dependencies
        uv pip install pytest requests
        
        # Verify torch is available from container
        uv run python -c "import torch; print(f'Using container PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"

    - name: Test CUDA availability
      run: |
        export PATH="$HOME/.local/bin:$PATH"
        uv run python -c "
        import torch
        print(f'PyTorch version: {torch.__version__}')
        print(f'CUDA available: {torch.cuda.is_available()}')
        if torch.cuda.is_available():
            print(f'CUDA version: {torch.version.cuda}')
            print(f'GPU count: {torch.cuda.device_count()}')
            for i in range(torch.cuda.device_count()):
                print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
        else:
            print('No CUDA GPUs detected (expected in GitHub Actions)')
        "

    - name: Add nanochat to PYTHONPATH
      run: |
        echo "PYTHONPATH=$(pwd):$PYTHONPATH" >> $GITHUB_ENV

    - name: Run CUDA tests
      run: |
        export PATH="$HOME/.local/bin:$PATH"
        uv run pytest tests/ --maxfail=5 -v 
