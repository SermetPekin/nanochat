name: Test

on:
  push:
    branches:
      - master
      - gh-wf-v3-local
  pull_request:
    branches:
      - master

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]   
        python-version: ['3.10'] 
      fail-fast: false

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Set up uv
      uses: astral-sh/setup-uv@v7

    - name: Install dependencies with uv
      run: |
        uv sync
        uv pip install transformers>=4.0.0

    - name: Add nanochat to PYTHONPATH (Unix)
      if: runner.os != 'Windows'
      run: |
        echo "PYTHONPATH=$(pwd):$PYTHONPATH" >> $GITHUB_ENV

    - name: Add nanochat to PYTHONPATH (Windows)
      if: runner.os == 'Windows'
      run: |
        echo "PYTHONPATH=$PWD;$env:PYTHONPATH" >> $env:GITHUB_ENV

    - name: Run pytest
      run: |
        uv run pytest tests/ --maxfail=5 

  test-cuda:
    runs-on: ubuntu-latest
    container:
      image: pytorch/pytorch:2.1.0-cuda11.8-cudnn8-devel
    strategy:
      matrix:
        python-version: ['3.10']
      fail-fast: false

    steps:
    - name: Install system dependencies
      run: |
        apt-get update
        apt-get install -y git curl

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up uv
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH

    - name: Install dependencies
      run: |
        ~/.cargo/bin/uv venv
        ~/.cargo/bin/uv sync
        ~/.cargo/bin/uv pip install transformers>=4.0.0

    - name: Test CUDA availability
      run: |
        ~/.cargo/bin/uv run python -c "
        import torch
        print(f'PyTorch version: {torch.__version__}')
        print(f'CUDA available: {torch.cuda.is_available()}')
        if torch.cuda.is_available():
            print(f'CUDA version: {torch.version.cuda}')
            print(f'GPU count: {torch.cuda.device_count()}')
            for i in range(torch.cuda.device_count()):
                print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
        else:
            print('No CUDA GPUs detected (expected in GitHub Actions)')
        "

    - name: Add nanochat to PYTHONPATH
      run: |
        echo "PYTHONPATH=$(pwd):$PYTHONPATH" >> $GITHUB_ENV

    - name: Run CUDA tests
      run: |
        ~/.cargo/bin/uv run pytest tests/ --maxfail=5 -v 
